{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4849d6",
   "metadata": {},
   "source": [
    "## Model Training and Initial Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b44f0485",
   "metadata": {},
   "source": [
    "This Kaggle competition requires that submissions be made by running code and creating an output file from a Kaggle notebook.\n",
    "I started by running a copy of the recommended tutorial notebook on Kaggle (https://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial/notebook).\n",
    "\n",
    "I let the notebook run to completion in an interactive session and tried to submit the result. At that point I learned that the run had taken 569 minutes, using a TPU, and that a maximum of 300 minutes run time was allowed for submission. I noted that the model had trained for 25 epochs. My second run was for 11 epochs, but again it ran too long at 307 minutes. My third run with 10 epochs ran in 300 minutes, and I was able to submit the result. This run produced a Kaggle score of 78.87916.\n",
    "\n",
    "I then investigated some of the other public notebooks for this competition, looking for improvement suggestions, including this one: https://www.kaggle.com/code/victorsullivan/i-m-something-of-a-painter-myself/notebook .\n",
    "I noted that the tutorial notebook used a batch size of one, and that many of the public notebooks were using a batch size of 32. Also the tutorial notebook was using tf.data.Dataset.zip to combine a sequence of 300 Monet images with a sequence of 7038 photos, and then training for a fixed number of epochs as in the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a04a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((monet_ds, photo_ds)),\n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab6c30",
   "metadata": {},
   "source": [
    "Zipping the two data sets as above means that the training data was always the 300 Monet images and only the first 300 photos, repeated for every epoch. To use repeating data sets instead, I borrowed the following blocks of code from the VictorSullivan notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cd422",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def get_gan_dataset(monet_files, photo_files, augment=None, repeat=True, shuffle=True, batch_size=1):\n",
    "\n",
    "    monet_ds = load_dataset(monet_files)\n",
    "    photo_ds = load_dataset(photo_files)\n",
    "    \n",
    "    if augment:\n",
    "        monet_ds = monet_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "        photo_ds = photo_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if repeat:\n",
    "        monet_ds = monet_ds.repeat()\n",
    "        photo_ds = photo_ds.repeat()\n",
    "        \n",
    "#     if shuffle:\n",
    "#         monet_ds = monet_ds.shuffle(2048)\n",
    "#         photo_ds = photo_ds.shuffle(2048)\n",
    "        \n",
    "    monet_ds = monet_ds.batch(batch_size, drop_remainder=True)\n",
    "    photo_ds = photo_ds.batch(batch_size, drop_remainder=True)\n",
    "#     monet_ds = monet_ds.cache()\n",
    "#     photo_ds = photo_ds.cache()\n",
    "    monet_ds = monet_ds.prefetch(AUTOTUNE)\n",
    "    photo_ds = photo_ds.prefetch(AUTOTUNE)\n",
    "    \n",
    "    gan_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
    "    \n",
    "    return gan_ds\n",
    "\n",
    "final_data_set = get_gan_dataset(MONET_FILENAMES, PHOTO_FILENAMES, augment=None, \n",
    "                                 repeat=True, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f63a6e",
   "metadata": {},
   "source": [
    "Using the final_data_set for training this way means that the Monet images and photos will each be repeated indefinitely as required. When using a repeating data set this way, the step_per_epoch parameter is needed to determine how many batches are processesed for each epoch of training -- as in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f14a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(final_data_set, epochs=28, steps_per_epoch=1490)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49ef2b",
   "metadata": {},
   "source": [
    "With these changes, I ran the model for 30 epochs of 1500 batches each, and got an improved Kaggle score of 40.66223 and a run time of 137 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84208f2d",
   "metadata": {},
   "source": [
    "I think the improvement in score resulted from 2 factors:\n",
    "    \n",
    "    * using the full set of photos instead of just the first 300\n",
    "    * effectively a lot more training time was availble because a batch size of 32 makes much more efficent use of the TPU versus a batch size of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d2686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
