{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9992c9c0",
   "metadata": {},
   "source": [
    "## Model Training and Initial Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "091647e9",
   "metadata": {},
   "source": [
    "This Kaggle competition requires that submissions be made by running code and creating an output file from a Kaggle notebook.\n",
    "I started by running a copy of the recommended tutorial notebook on Kaggle (https://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial/notebook).\n",
    "\n",
    "I let the notebook run to completion in an interactive session and tried to submit the result. At that point I learned that the run had taken 569 minutes, using a TPU, and that a maximum of 300 minutes run time was allowed for submission. I noted that the model had trained for 25 epochs. My second run was for 11 epochs, but again it ran too long at 307 minutes. My third run with 10 epochs ran in 300 minutes, and I was able to submit the result. This run produced a Kaggle score of 78.87916.\n",
    "\n",
    "I then investigated some of the other public notebooks for this competition, looking for improvement suggestions, including this one: https://www.kaggle.com/code/victorsullivan/i-m-something-of-a-painter-myself/notebook .\n",
    "I noted that the tutorial notebook used a batch size of one, and that many of the public notebooks were using a batch size of 32. Also the tutorial notebook was using tf.data.Dataset.zip to combine a sequence of 300 Monet images with a sequence of 7038 photos, and then training for a fixed number of epochs as in the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((monet_ds, photo_ds)),\n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eaa401",
   "metadata": {},
   "source": [
    "Zipping the two data sets as above means that the training data was always the 300 Monet images and only the first 300 photos, repeated for every epoch. To use repeating data sets instead, I borrowed the following blocks of code from the VictorSullivan notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def get_gan_dataset(monet_files, photo_files, augment=None, repeat=True, shuffle=True, batch_size=1):\n",
    "\n",
    "    monet_ds = load_dataset(monet_files)\n",
    "    photo_ds = load_dataset(photo_files)\n",
    "    \n",
    "    if augment:\n",
    "        monet_ds = monet_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "        photo_ds = photo_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if repeat:\n",
    "        monet_ds = monet_ds.repeat()\n",
    "        photo_ds = photo_ds.repeat()\n",
    "        \n",
    "#     if shuffle:\n",
    "#         monet_ds = monet_ds.shuffle(2048)\n",
    "#         photo_ds = photo_ds.shuffle(2048)\n",
    "        \n",
    "    monet_ds = monet_ds.batch(batch_size, drop_remainder=True)\n",
    "    photo_ds = photo_ds.batch(batch_size, drop_remainder=True)\n",
    "#     monet_ds = monet_ds.cache()\n",
    "#     photo_ds = photo_ds.cache()\n",
    "    monet_ds = monet_ds.prefetch(AUTOTUNE)\n",
    "    photo_ds = photo_ds.prefetch(AUTOTUNE)\n",
    "    \n",
    "    gan_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
    "    \n",
    "    return gan_ds\n",
    "\n",
    "final_data_set = get_gan_dataset(MONET_FILENAMES, PHOTO_FILENAMES, augment=None, \n",
    "                                 repeat=True, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e0323",
   "metadata": {},
   "source": [
    "Using the final_data_set for training this way means that the Monet images and photos will each be repeated indefinitely as required. When using a repeating data set this way, the step_per_epoch parameter is needed to determine how many batches are processesed for each epoch of training -- as in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(final_data_set, epochs=28, steps_per_epoch=1490)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afbe27",
   "metadata": {},
   "source": [
    "With these changes, I ran the model for 30 epochs of 1500 batches each, and got an improved Kaggle score of 40.66223 and a run time of 137 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dee3a",
   "metadata": {},
   "source": [
    "I think the improvement in score resulted from 2 factors:\n",
    "    \n",
    "* using the full set of photos instead of just the first 300\n",
    "* effectively a lot more training time was availble because a batch size of 32 makes much more efficent use of the TPU versus a batch size of one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b139d10",
   "metadata": {},
   "source": [
    "Next we tried to improve the score by varying the the number of epochs or the total number of batches used for training. With the CycleGAN models it is hard to know how much training will give the best result. With a typical supervised learning problem we could use a validation loss score and early stopping to train just the right number of iterations and avoid overfitting. But with GAN models, the discriminators and generators are both improving as long as the losses stay relatively balanced. There is not an objective way to know when to stop based on the losses. I tried varying the lenght of training of this same model for a number of runs with the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0894f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version Label</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Steps per Epoch</th>\n",
       "      <th>Training Batches</th>\n",
       "      <th>Kaggle Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V5</td>\n",
       "      <td>30</td>\n",
       "      <td>1500</td>\n",
       "      <td>45000</td>\n",
       "      <td>40.66223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V7</td>\n",
       "      <td>40</td>\n",
       "      <td>1500</td>\n",
       "      <td>60000</td>\n",
       "      <td>41.00751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V11</td>\n",
       "      <td>34</td>\n",
       "      <td>1500</td>\n",
       "      <td>51000</td>\n",
       "      <td>42.23765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V12</td>\n",
       "      <td>28</td>\n",
       "      <td>1500</td>\n",
       "      <td>42000</td>\n",
       "      <td>38.89318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V14</td>\n",
       "      <td>26</td>\n",
       "      <td>1500</td>\n",
       "      <td>39000</td>\n",
       "      <td>45.92713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V15</td>\n",
       "      <td>29</td>\n",
       "      <td>1500</td>\n",
       "      <td>43500</td>\n",
       "      <td>50.34030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V17</td>\n",
       "      <td>27</td>\n",
       "      <td>1500</td>\n",
       "      <td>40500</td>\n",
       "      <td>41.37489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V18</td>\n",
       "      <td>28</td>\n",
       "      <td>1500</td>\n",
       "      <td>42000</td>\n",
       "      <td>38.36144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V19</td>\n",
       "      <td>28</td>\n",
       "      <td>1480</td>\n",
       "      <td>41440</td>\n",
       "      <td>40.81393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V20</td>\n",
       "      <td>28</td>\n",
       "      <td>1510</td>\n",
       "      <td>42280</td>\n",
       "      <td>40.34160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V21</td>\n",
       "      <td>28</td>\n",
       "      <td>1490</td>\n",
       "      <td>41720</td>\n",
       "      <td>39.17955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V22</td>\n",
       "      <td>28</td>\n",
       "      <td>1490</td>\n",
       "      <td>41720</td>\n",
       "      <td>38.85488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V23</td>\n",
       "      <td>28</td>\n",
       "      <td>1490</td>\n",
       "      <td>41720</td>\n",
       "      <td>41.32099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V24</td>\n",
       "      <td>28</td>\n",
       "      <td>1490</td>\n",
       "      <td>41720</td>\n",
       "      <td>40.31779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V28</td>\n",
       "      <td>28</td>\n",
       "      <td>1490</td>\n",
       "      <td>41720</td>\n",
       "      <td>41.21607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V33</td>\n",
       "      <td>80</td>\n",
       "      <td>750</td>\n",
       "      <td>60000</td>\n",
       "      <td>41.28135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V34</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>15000</td>\n",
       "      <td>37.37401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V35</td>\n",
       "      <td>15</td>\n",
       "      <td>750</td>\n",
       "      <td>11250</td>\n",
       "      <td>40.19198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V36</td>\n",
       "      <td>22</td>\n",
       "      <td>750</td>\n",
       "      <td>16500</td>\n",
       "      <td>39.25218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V37</td>\n",
       "      <td>18</td>\n",
       "      <td>750</td>\n",
       "      <td>13500</td>\n",
       "      <td>43.32290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>V38</td>\n",
       "      <td>21</td>\n",
       "      <td>750</td>\n",
       "      <td>15750</td>\n",
       "      <td>40.36929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>V39</td>\n",
       "      <td>19</td>\n",
       "      <td>750</td>\n",
       "      <td>14250</td>\n",
       "      <td>40.97442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>V40</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>15000</td>\n",
       "      <td>37.81132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>V41</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>15000</td>\n",
       "      <td>39.12494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>V42</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>15000</td>\n",
       "      <td>40.38943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>V43</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>15000</td>\n",
       "      <td>41.99573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version Label  Epochs  Steps per Epoch  Training Batches  Kaggle Score\n",
       "0             V5      30             1500             45000      40.66223\n",
       "1             V7      40             1500             60000      41.00751\n",
       "2            V11      34             1500             51000      42.23765\n",
       "3           V12       28             1500             42000      38.89318\n",
       "4            V14      26             1500             39000      45.92713\n",
       "5            V15      29             1500             43500      50.34030\n",
       "6            V17      27             1500             40500      41.37489\n",
       "7            V18      28             1500             42000      38.36144\n",
       "8            V19      28             1480             41440      40.81393\n",
       "9            V20      28             1510             42280      40.34160\n",
       "10           V21      28             1490             41720      39.17955\n",
       "11           V22      28             1490             41720      38.85488\n",
       "12           V23      28             1490             41720      41.32099\n",
       "13           V24      28             1490             41720      40.31779\n",
       "14           V28      28             1490             41720      41.21607\n",
       "15           V33      80              750             60000      41.28135\n",
       "16           V34      20              750             15000      37.37401\n",
       "17           V35      15              750             11250      40.19198\n",
       "18           V36      22              750             16500      39.25218\n",
       "19           V37      18              750             13500      43.32290\n",
       "20           V38      21              750             15750      40.36929\n",
       "21           V39      19              750             14250      40.97442\n",
       "22           V40      20              750             15000      37.81132\n",
       "23           V41      20              750             15000      39.12494\n",
       "24           V42      20              750             15000      40.38943\n",
       "25           V43      20              750             15000      41.99573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('./kaggle_scores_01.xlsx')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f08f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
